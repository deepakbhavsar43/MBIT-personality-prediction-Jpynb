{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas import *\n",
        "from sklearn import *\n",
        "from sklearn.metrics import *\n",
        "from numpy import *\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn.model_selection import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3062: DtypeWarning: Columns (162,163,164,165,166,167,168,169,170,171,172,173,174,175,178,179,180,181,182,183,184,185,186,187,188,191,192,193,194,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
          ]
        }
      ],
      "source": [
        "path=r\"C:\\Users\\hp\\Downloads\\mbti_personality_classification_ai_challenge-dataset\\TRAIN.csv\"\n",
        "data=read_csv(path)\n",
        "data=data[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "def collect_text(i):\n",
        "    res=[]\n",
        "    for j in data.iloc[i,2:]:\n",
        "        if j:\n",
        "            res.append(str(j))\n",
        "        else:\n",
        "            break\n",
        "    res=''.join(res)\n",
        "    res=res.replace(\"nan\",\"\")\n",
        "    res=res.translate(str.maketrans('','',string.punctuation))\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ENFP</td>\n",
              "      <td>I like that you are kind as INFJ I find that I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>Oh my you are right Who really talks like tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>INFP</td>\n",
              "      <td>yep yep yep especially the last one    yep agr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>Things that are generalizable to the entire po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>Work Student   Hobbies Studying gaming reading...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id label                                               text\n",
              "0   0  ENFP  I like that you are kind as INFJ I find that I...\n",
              "1   1  INFJ   Oh my you are right Who really talks like tha...\n",
              "2   2  INFP  yep yep yep especially the last one    yep agr...\n",
              "3   3  INFJ  Things that are generalizable to the entire po...\n",
              "4   4  INTJ  Work Student   Hobbies Studying gaming reading..."
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newdata=DataFrame()\n",
        "newdata['id']=data.iloc[:,0]\n",
        "newdata['label']=data.iloc[:,1]\n",
        "x=[]\n",
        "for i in range(len(data)):\n",
        "    x.append(collect_text(i))\n",
        "newdata['text']=x\n",
        "newdata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "x=newdata['text']\n",
        "y=newdata['label']\n",
        "from sklearn.preprocessing import *\n",
        "encode=LabelEncoder()\n",
        "y=encode.fit_transform(y)\n",
        "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv=CountVectorizer()\n",
        "train_x_cv=cv.fit_transform(train_x).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=MultinomialNB()\n",
        "model.fit(train_x_cv,train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ENTJ', 'INTJ', 'INFP', 'ISFP', 'ENFP', 'ESTJ', 'ENFJ', 'ESFP', 'INTP', 'ISTP', 'INFJ', 'ISTJ', 'ESTP', 'ENTP', 'ISFJ', 'ESFJ'}\n"
          ]
        }
      ],
      "source": [
        "res=encode.inverse_transform(train_y)\n",
        "print(set(res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 8  8  8  8  8  9  8  9  9  8  8  9  9  8  8  8  8  9  9  8  8  8  9  9\n",
            "  9  9  8  8  8  8  8  8  8  9  8  8  8  9  8  8  8  8  9  9  8  9  9  9\n",
            "  9  8  8  8  8  9  8  8  9  9  9  8  9  9  8  8  9  9  8  8  9  8  8  8\n",
            "  8  9  8  8  8  9  9  9  8  9  9  8  9  9  9  8  8  8  8  9  9  8  9  8\n",
            "  9  8  8  8  8  9  8  8  8  8  8  9  8  9  8  9  9  8  8  9  9  8  8  8\n",
            "  8  8  8  8  9  8  8  8  8  8  9  9  8  8  9  9  8  9 11  8  9  9  8  9\n",
            "  8  8  9  9  8  9  8  8  8  8  8  8  8  8  9  8  8  8  8  8  8  8  9  9\n",
            "  8  8  9  9  8  8  8  8  8  8  9  9  9  8  8  8  8  8  8  9  8  8  8  8\n",
            "  9  9  8  8  9  9  8  8  9  9  8  9  8  8  9  8  9  9  9  8  8  8  9  8\n",
            "  9  8  8  8  9  8  8  8  8  9  8  8  9  8  8  8  9  9  8  8  8  8  9  8\n",
            "  8  8  9  8  8  8  8  8  8  8]\n"
          ]
        }
      ],
      "source": [
        "test_x_cv=cv.transform(test_x).toarray()\n",
        "output=model.predict(test_x_cv)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.888444419044716\n"
          ]
        }
      ],
      "source": [
        "print(sqrt(mean_squared_error(output,test_y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFP' 'INFP' 'INFJ'\n",
            " 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ'\n",
            " 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFJ'\n",
            " 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFJ'\n",
            " 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFP' 'INFP' 'INFP' 'INFJ'\n",
            " 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFP' 'INFJ'\n",
            " 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFJ'\n",
            " 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFP'\n",
            " 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFJ'\n",
            " 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFP' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFJ'\n",
            " 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFP'\n",
            " 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFJ'\n",
            " 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ'\n",
            " 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFP' 'INTP' 'INFJ'\n",
            " 'INFP' 'INFP' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFP'\n",
            " 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ'\n",
            " 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFJ'\n",
            " 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFP'\n",
            " 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFJ'\n",
            " 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFJ'\n",
            " 'INFP' 'INFP' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFP' 'INFP'\n",
            " 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFJ'\n",
            " 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFP' 'INFJ'\n",
            " 'INFJ' 'INFJ' 'INFP' 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFP' 'INFJ'\n",
            " 'INFJ' 'INFJ' 'INFP' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ' 'INFJ']\n"
          ]
        }
      ],
      "source": [
        "new_output=encode.inverse_transform(output)\n",
        "print(new_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>posts</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "      <th>Unnamed: 8</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>...</th>\n",
              "      <th>Unnamed: 249</th>\n",
              "      <th>Unnamed: 250</th>\n",
              "      <th>Unnamed: 251</th>\n",
              "      <th>Unnamed: 252</th>\n",
              "      <th>Unnamed: 253</th>\n",
              "      <th>Unnamed: 254</th>\n",
              "      <th>Unnamed: 255</th>\n",
              "      <th>Unnamed: 256</th>\n",
              "      <th>Unnamed: 257</th>\n",
              "      <th>Unnamed: 258</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>'So true!  I said earlier that my face was ver...</td>\n",
              "      <td>I think I finally figured out why your sudden...</td>\n",
              "      <td>to person-who-wants-to-pretend-we're-just-cas...</td>\n",
              "      <td>needles</td>\n",
              "      <td>etc.).  I can't handle pain mixed with pressure</td>\n",
              "      <td>though.  I had so many people tell me that</td>\n",
              "      <td>because of the drugs/epidural</td>\n",
              "      <td>I...|||My husband and I are INFP/ESTJ</td>\n",
              "      <td>too!  It's so rare to come across that.  Real...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>'Congrats</td>\n",
              "      <td>Spades. You are just TOO awesome. And give a ...</td>\n",
              "      <td>girl!|||I am certainly the same way. It nearl...</td>\n",
              "      <td>in that</td>\n",
              "      <td>of all the things about me as an individual t...</td>\n",
              "      <td>which is what I value least...|||I wonder too...</td>\n",
              "      <td>a parent will halt any discussions with a chi...</td>\n",
              "      <td>whereas a friend is on more even...|||Welcome...</td>\n",
              "      <td>median and standard deviation for the age bra...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>@BrokenGenius  Here is an alternate perspectiv...</td>\n",
              "      <td>more so if you're in the same generation. If not</td>\n",
              "      <td>...|||I made friends easiest by asking people ...</td>\n",
              "      <td>use your Ne. It is easy to attack them in are...</td>\n",
              "      <td>offer multiple alternate perspectives on the ...</td>\n",
              "      <td>as they will...|||One is like an emo nerd and...</td>\n",
              "      <td>people are lazy to find their facts themselves</td>\n",
              "      <td>regardless of their position on this matter.|...</td>\n",
              "      <td>any ENTP-INFJ relationship or anything else w...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>'Yeah</td>\n",
              "      <td>I realize that now.|||The Trio   Mugen - ESTP...</td>\n",
              "      <td>however</td>\n",
              "      <td>I'd be willing to entertain him being an INTJ...</td>\n",
              "      <td>he seems more Si - Te...|||Apparently</td>\n",
              "      <td>there's someone else writing the script</td>\n",
              "      <td>he just says it and makes the jokes. On that ...</td>\n",
              "      <td>he's probably an ENTP.|||Okay</td>\n",
              "      <td>so I just rewatched the series after four yea...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>'Oh</td>\n",
              "      <td>hehe. Thanks</td>\n",
              "      <td>buddy. (That's just me wanting to sound overl...</td>\n",
              "      <td>as I do in my overactive imagination</td>\n",
              "      <td>but then settling for what the reality check ...</td>\n",
              "      <td>in ways. In my head</td>\n",
              "      <td>my life has background score. Which really st...</td>\n",
              "      <td>INFJs are just cautious by nature when it com...</td>\n",
              "      <td>there's a vast improvement. Most of it comes ...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 259 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   idx                                              posts  \\\n",
              "0    0  'So true!  I said earlier that my face was ver...   \n",
              "1    1                                          'Congrats   \n",
              "2    2  @BrokenGenius  Here is an alternate perspectiv...   \n",
              "3    3                                              'Yeah   \n",
              "4    4                                                'Oh   \n",
              "\n",
              "                                          Unnamed: 2  \\\n",
              "0   I think I finally figured out why your sudden...   \n",
              "1   Spades. You are just TOO awesome. And give a ...   \n",
              "2   more so if you're in the same generation. If not   \n",
              "3   I realize that now.|||The Trio   Mugen - ESTP...   \n",
              "4                                       hehe. Thanks   \n",
              "\n",
              "                                          Unnamed: 3  \\\n",
              "0   to person-who-wants-to-pretend-we're-just-cas...   \n",
              "1   girl!|||I am certainly the same way. It nearl...   \n",
              "2  ...|||I made friends easiest by asking people ...   \n",
              "3                                            however   \n",
              "4   buddy. (That's just me wanting to sound overl...   \n",
              "\n",
              "                                          Unnamed: 4  \\\n",
              "0                                            needles   \n",
              "1                                            in that   \n",
              "2   use your Ne. It is easy to attack them in are...   \n",
              "3   I'd be willing to entertain him being an INTJ...   \n",
              "4               as I do in my overactive imagination   \n",
              "\n",
              "                                          Unnamed: 5  \\\n",
              "0    etc.).  I can't handle pain mixed with pressure   \n",
              "1   of all the things about me as an individual t...   \n",
              "2   offer multiple alternate perspectives on the ...   \n",
              "3              he seems more Si - Te...|||Apparently   \n",
              "4   but then settling for what the reality check ...   \n",
              "\n",
              "                                          Unnamed: 6  \\\n",
              "0         though.  I had so many people tell me that   \n",
              "1   which is what I value least...|||I wonder too...   \n",
              "2   as they will...|||One is like an emo nerd and...   \n",
              "3            there's someone else writing the script   \n",
              "4                                in ways. In my head   \n",
              "\n",
              "                                          Unnamed: 7  \\\n",
              "0                      because of the drugs/epidural   \n",
              "1   a parent will halt any discussions with a chi...   \n",
              "2     people are lazy to find their facts themselves   \n",
              "3   he just says it and makes the jokes. On that ...   \n",
              "4   my life has background score. Which really st...   \n",
              "\n",
              "                                          Unnamed: 8  \\\n",
              "0              I...|||My husband and I are INFP/ESTJ   \n",
              "1   whereas a friend is on more even...|||Welcome...   \n",
              "2   regardless of their position on this matter.|...   \n",
              "3                      he's probably an ENTP.|||Okay   \n",
              "4   INFJs are just cautious by nature when it com...   \n",
              "\n",
              "                                          Unnamed: 9  ... Unnamed: 249  \\\n",
              "0   too!  It's so rare to come across that.  Real...  ...          NaN   \n",
              "1   median and standard deviation for the age bra...  ...          NaN   \n",
              "2   any ENTP-INFJ relationship or anything else w...  ...          NaN   \n",
              "3   so I just rewatched the series after four yea...  ...          NaN   \n",
              "4   there's a vast improvement. Most of it comes ...  ...          NaN   \n",
              "\n",
              "  Unnamed: 250 Unnamed: 251 Unnamed: 252 Unnamed: 253 Unnamed: 254  \\\n",
              "0          NaN          NaN          NaN          NaN          NaN   \n",
              "1          NaN          NaN          NaN          NaN          NaN   \n",
              "2          NaN          NaN          NaN          NaN          NaN   \n",
              "3          NaN          NaN          NaN          NaN          NaN   \n",
              "4          NaN          NaN          NaN          NaN          NaN   \n",
              "\n",
              "  Unnamed: 255 Unnamed: 256 Unnamed: 257 Unnamed: 258  \n",
              "0          NaN          NaN          NaN          NaN  \n",
              "1          NaN          NaN          NaN          NaN  \n",
              "2          NaN          NaN          NaN          NaN  \n",
              "3          NaN          NaN          NaN          NaN  \n",
              "4          NaN          NaN          NaN          NaN  \n",
              "\n",
              "[5 rows x 259 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path1=r\"C:\\Users\\hp\\Downloads\\mbti_personality_classification_ai_challenge-dataset\\TEST.csv\"\n",
        "test_data=read_csv(path1)\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "result=DataFrame()\n",
        "result['idx']=test_data['idx']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "def collect_text1(i):\n",
        "    res=[]\n",
        "    for j in test_data.iloc[i,1:]:\n",
        "        if j:\n",
        "            res.append(str(j))\n",
        "        else:\n",
        "            break\n",
        "    res=''.join(res)\n",
        "    res=res.replace(\"nan\",\"\")\n",
        "    res=res.translate(str.maketrans('','',string.punctuation))\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_test=[]\n",
        "for i in range(len(test_data)):\n",
        "    new_test.append(collect_text1(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_test_cv=cv.transform(new_test).toarray()\n",
        "final=model.predict(new_test_cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['INFP' 'INFP' 'ENTP' ... 'INFJ' 'INFJ' 'INFP']\n"
          ]
        }
      ],
      "source": [
        "new_final=encode.inverse_transform(final)\n",
        "print(new_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of        idx  type\n",
            "0        0  INFP\n",
            "1        1  INFP\n",
            "2        2  ENTP\n",
            "3        3  INFJ\n",
            "4        4  INFJ\n",
            "...    ...   ...\n",
            "1730  1730  INFP\n",
            "1731  1731  INFJ\n",
            "1732  1732  INFJ\n",
            "1733  1733  INFJ\n",
            "1734  1734  INFP\n",
            "\n",
            "[1735 rows x 2 columns]>\n"
          ]
        }
      ],
      "source": [
        "result['type']=new_final\n",
        "print(result.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "result.to_csv(\"result_new.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}